# ğŸ“ Guia de Estudo: Agente de Pesquisa LangGraph + Gemini

## ğŸ“‹ VisÃ£o Geral do Projeto

Este Ã© um agente de pesquisa inteligente que:
- âœ… Gera queries de busca otimizadas
- âœ… Realiza pesquisa web usando Google Search API
- âœ… Reflete sobre resultados e identifica lacunas
- âœ… Sintetiza resposta final com citaÃ§Ãµes

## ğŸ—ï¸ Arquitetura Principal

```
backend/src/agent/
â”œâ”€â”€ graph.py          # â­ NÃšCLEO: Grafo de estados LangGraph
â”œâ”€â”€ state.py          # ğŸ“Š Estados e tipos de dados
â”œâ”€â”€ configuration.py  # âš™ï¸ ConfiguraÃ§Ãµes do agente
â”œâ”€â”€ prompts.py        # ğŸ¯ Prompts para IA generativa
â”œâ”€â”€ tools_and_schemas.py # ğŸ› ï¸ Schemas estruturados
â”œâ”€â”€ utils.py          # ğŸ”§ UtilitÃ¡rios e citaÃ§Ãµes
â””â”€â”€ app.py           # ğŸš€ FastAPI server
```

## ğŸ“š Plano de Estudo PrÃ¡tico

### 1ï¸âƒ£ **PRIMEIRO PASSO: Executar o Exemplo**

```bash
# Configurar ambiente
cd backend
pip install .

# Criar .env com sua GEMINI_API_KEY
echo "GEMINI_API_KEY=sua_chave_aqui" > .env

# Testar o agente
python examples/cli_research.py "What are the latest trends in renewable energy?"
```

**ğŸ¯ Objetivo**: Ver o agente funcionando antes de estudar o cÃ³digo

---

### 2ï¸âƒ£ **ENTENDER OS ESTADOS (state.py)**

#### Estados Principais:
- **OverallState**: Estado global do agente
- **QueryGenerationState**: Para geraÃ§Ã£o de queries
- **WebSearchState**: Para pesquisa web
- **ReflectionState**: Para reflexÃ£o e anÃ¡lise

#### ğŸ’¡ ExercÃ­cio PrÃ¡tico:
```python
# Teste no Python REPL
from agent.state import OverallState
from langchain_core.messages import HumanMessage

# Simule um estado inicial
state = {
    "messages": [HumanMessage(content="What is AI?")],
    "search_query": [],
    "web_research_result": [],
    "sources_gathered": [],
    "initial_search_query_count": 3,
    "max_research_loops": 2,
    "research_loop_count": 0,
    "reasoning_model": "gemini-2.5-pro"
}
```

---

### 3ï¸âƒ£ **ESTUDAR CONFIGURAÃ‡ÃƒO (configuration.py)**

#### ParÃ¢metros ConfigurÃ¡veis:
- **query_generator_model**: "gemini-2.0-flash"
- **reflection_model**: "gemini-2.5-flash" 
- **answer_model**: "gemini-2.5-pro"
- **number_of_initial_queries**: 3
- **max_research_loops**: 2

#### ğŸ’¡ ExercÃ­cio PrÃ¡tico:
```python
from agent.configuration import Configuration

# Teste diferentes configuraÃ§Ãµes
config = Configuration(
    max_research_loops=5,
    number_of_initial_queries=5
)
print(f"Loops mÃ¡ximos: {config.max_research_loops}")
print(f"Queries iniciais: {config.number_of_initial_queries}")
```

---

### 4ï¸âƒ£ **ANALISAR PROMPTS (prompts.py)**

#### 4 Tipos de Prompts:

1. **query_writer_instructions**: Gera queries de busca
2. **web_searcher_instructions**: Dirige a pesquisa web
3. **reflection_instructions**: Analisa resultados
4. **answer_instructions**: Sintetiza resposta final

#### ğŸ’¡ ExercÃ­cio PrÃ¡tico:
```python
from agent.prompts import query_writer_instructions, get_current_date

# Teste formataÃ§Ã£o de prompt
current_date = get_current_date()
formatted_prompt = query_writer_instructions.format(
    current_date=current_date,
    research_topic="Latest AI developments",
    number_queries=3
)
print(formatted_prompt)
```

---

### 5ï¸âƒ£ **COMPREENDER O GRAFO (graph.py)**

#### Fluxo de ExecuÃ§Ã£o:
```
START â†’ generate_query â†’ web_research â†’ reflection â†’ finalize_answer â†’ END
                            â†‘              â†“
                            â””â”€â”€ (se insuficiente)
```

#### NÃ³s Principais:

##### ğŸ” **generate_query()**
```python
# O que faz:
# 1. Recebe pergunta do usuÃ¡rio
# 2. Usa Gemini 2.0 Flash para gerar queries
# 3. Retorna lista de queries otimizadas
```

##### ğŸŒ **web_research()**  
```python
# O que faz:
# 1. Executa busca usando Google Search API
# 2. Processa resultados com grounding metadata
# 3. Gera citaÃ§Ãµes e resolve URLs
```

##### ğŸ¤” **reflection()**
```python
# O que faz:
# 1. Analisa resultados da pesquisa
# 2. Identifica lacunas de conhecimento
# 3. Decide se precisa mais pesquisa
# 4. Gera queries de follow-up se necessÃ¡rio
```

##### âœ… **finalize_answer()**
```python
# O que faz:
# 1. Sintetiza todos os resultados
# 2. Cria resposta final estruturada
# 3. Inclui citaÃ§Ãµes apropriadas
```

#### ğŸ’¡ ExercÃ­cio PrÃ¡tico:
```python
# Teste nÃ³s individuais
from agent.graph import generate_query
from langchain_core.messages import HumanMessage

state = {
    "messages": [HumanMessage(content="What is quantum computing?")],
    "initial_search_query_count": 3
}

# Simule configuraÃ§Ã£o (vocÃª precisarÃ¡ de uma API key vÃ¡lida)
# result = generate_query(state, config={})
# print(result)
```

---

### 6ï¸âƒ£ **UTILITÃRIOS E CITAÃ‡Ã•ES (utils.py)**

#### FunÃ§Ãµes Importantes:

##### ğŸ”— **get_citations()**
```python
# Extrai citaÃ§Ãµes da resposta do Gemini
# Cria links formatados para fontes
```

##### ğŸŒ **resolve_urls()**
```python
# Converte URLs longas em URLs curtas
# MantÃ©m mapeamento para citaÃ§Ãµes
```

##### ğŸ“ **insert_citation_markers()**
```python
# Insere marcadores de citaÃ§Ã£o no texto
# Formata como links markdown
```

#### ğŸ’¡ ExercÃ­cio PrÃ¡tico:
```python
from agent.utils import get_research_topic
from langchain_core.messages import HumanMessage, AIMessage

# Teste extraÃ§Ã£o de tÃ³pico
messages = [
    HumanMessage(content="What is machine learning?"),
    AIMessage(content="Machine learning is..."),
    HumanMessage(content="Tell me more about neural networks")
]

topic = get_research_topic(messages)
print(f"TÃ³pico extraÃ­do: {topic}")
```

---

## ğŸ”¬ Experimentos AvanÃ§ados

### Experimento 1: Modificar NÃºmero de Queries
```python
# Teste com diferentes nÃºmeros de queries iniciais
for num_queries in [1, 3, 5]:
    print(f"\n=== Testando com {num_queries} queries ===")
    # Execute o agente com essa configuraÃ§Ã£o
```

### Experimento 2: Diferentes Modelos
```python
# Teste diferentes modelos Gemini
models = ["gemini-2.0-flash", "gemini-2.5-flash", "gemini-2.5-pro"]
for model in models:
    print(f"\n=== Testando com {model} ===")
    # Execute com cada modelo
```

### Experimento 3: Customizar Prompts
```python
# Modifique prompts para domÃ­nios especÃ­ficos
custom_prompt = """
VocÃª Ã© um especialista em tecnologia.
Gere queries tÃ©cnicas especÃ­ficas sobre: {research_topic}
...
"""
```

## ğŸ¯ Desafios PrÃ¡ticos

### Desafio 1: Agente de Pesquisa AcadÃªmica
- Modifique prompts para buscar papers acadÃªmicos
- Adicione filtros por data de publicaÃ§Ã£o
- Implemente citaÃ§Ãµes no formato ABNT

### Desafio 2: Agente de AnÃ¡lise de Mercado
- Foque em dados financeiros e tendÃªncias
- Adicione anÃ¡lise de sentimentos
- Gere relatÃ³rios estruturados

### Desafio 3: Sistema de VerificaÃ§Ã£o de Fatos
- Implemente verificaÃ§Ã£o cruzada de fontes
- Adicione scoring de credibilidade
- Detecte informaÃ§Ãµes contraditÃ³rias

## ğŸ“Š MÃ©tricas para Acompanhar

1. **NÃºmero de queries geradas**
2. **NÃºmero de loops de pesquisa**
3. **Qualidade das fontes encontradas**
4. **Tempo de execuÃ§Ã£o total**
5. **PrecisÃ£o das respostas**

## ğŸš€ PrÃ³ximos Passos

1. **Entenda cada arquivo individualmente**
2. **Execute experimentos prÃ¡ticos**
3. **Modifique configuraÃ§Ãµes gradualmente**
4. **Implemente suas prÃ³prias customizaÃ§Ãµes**
5. **Crie novos tipos de agentes**

---

## ğŸ“š Recursos Adicionais

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [Google Gemini API](https://ai.google.dev/docs)
- [LangChain Agents Guide](https://python.langchain.com/docs/use_cases/autonomous_agents/)

**Boa sorte nos seus estudos! ğŸ‰**