#!/usr/bin/env python3
"""
ğŸ¯ EXERCÃCIO 5: CustomizaÃ§Ãµes e Experimentos
Objetivo: Modificar e personalizar o agente para diferentes casos de uso
"""

import os
import sys
sys.path.append('../backend/src')

from agent.prompts import (
    query_writer_instructions,
    web_searcher_instructions,
    reflection_instructions,
    answer_instructions,
    get_current_date
)
from agent.configuration import Configuration
from agent.graph import graph
from langchain_core.messages import HumanMessage

def exercicio_1_prompt_personalizado():
    """Crie prompts personalizados para domÃ­nios especÃ­ficos"""
    print("ğŸ¨ EXERCÃCIO 1: Prompts Personalizados")
    print("=" * 45)
    
    # Prompt para pesquisa acadÃªmica
    prompt_academico = """VocÃª Ã© um assistente de pesquisa acadÃªmica especializado.
Sua tarefa Ã© gerar consultas de pesquisa para artigos cientÃ­ficos e papers acadÃªmicos.

InstruÃ§Ãµes:
- Foque em termos tÃ©cnicos e cientÃ­ficos
- Inclua anos recentes (2020-2024)
- Busque por papers peer-reviewed
- Use termos em inglÃªs para melhor cobertura
- Prefira queries que encontrem artigos de revistas conceituadas

TÃ³pico de pesquisa: {research_topic}
Data atual: {current_date}
NÃºmero de queries desejadas: {number_queries}

Formato da resposta:
{{
    "rationale": "ExplicaÃ§Ã£o tÃ©cnica da estratÃ©gia de busca",
    "query": ["query1", "query2", "query3"]
}}

Contexto: {research_topic}"""

    # Prompt para anÃ¡lise de mercado
    prompt_mercado = """VocÃª Ã© um analista de mercado especializado em tendÃªncias comerciais.
Sua tarefa Ã© gerar consultas para pesquisa de dados de mercado, tendÃªncias e oportunidades.

InstruÃ§Ãµes:
- Foque em dados financeiros e de mercado
- Inclua termos como "market trends", "revenue", "growth"
- Busque por relatÃ³rios de empresas e anÃ¡lises
- Considere diferentes geografias (global, regional)
- Inclua aspectos de competitividade

TÃ³pico: {research_topic}
Data: {current_date}
Queries: {number_queries}

Formato:
{{
    "rationale": "EstratÃ©gia de anÃ¡lise de mercado",
    "query": ["query comercial 1", "query comercial 2"]
}}

Contexto: {research_topic}"""

    # Prompt para verificaÃ§Ã£o de fatos
    prompt_verificacao = """VocÃª Ã© um verificador de fatos especializado em anÃ¡lise crÃ­tica.
Sua tarefa Ã© gerar consultas para verificar a veracidade de informaÃ§Ãµes.

InstruÃ§Ãµes:
- Busque mÃºltiplas fontes independentes
- Inclua termos como "fact check", "verified", "official"
- Procure por fontes governamentais e organizaÃ§Ãµes confiÃ¡veis
- Considere diferentes perspectivas
- Foque em evidÃªncias e dados verificÃ¡veis

AfirmaÃ§Ã£o a verificar: {research_topic}
Data: {current_date}
Queries: {number_queries}

Formato:
{{
    "rationale": "EstratÃ©gia de verificaÃ§Ã£o",
    "query": ["verificaÃ§Ã£o 1", "verificaÃ§Ã£o 2"]
}}

Contexto: {research_topic}"""

    prompts_personalizados = {
        "acadÃªmico": prompt_academico,
        "mercado": prompt_mercado,
        "verificaÃ§Ã£o": prompt_verificacao
    }
    
    print("ğŸ“š Prompts criados:")
    for nome, prompt in prompts_personalizados.items():
        tamanho = len(prompt)
        print(f"  - {nome.capitalize()}: {tamanho} caracteres")
    
    # Teste um prompt
    print(f"\nğŸ§ª Teste do prompt acadÃªmico:")
    topico = "machine learning applications in healthcare"
    prompt_formatado = prompts_personalizados["acadÃªmico"].format(
        research_topic=topico,
        current_date=get_current_date(),
        number_queries=3
    )
    print(f"ğŸ“‹ Prompt formatado (primeiros 300 chars):")
    print(prompt_formatado[:300] + "...")
    
    return prompts_personalizados

def exercicio_2_configuracoes_especializadas():
    """Crie configuraÃ§Ãµes para diferentes casos de uso"""
    print("\nâš™ï¸ EXERCÃCIO 2: ConfiguraÃ§Ãµes Especializadas")
    print("=" * 50)
    
    # ConfiguraÃ§Ã£o para pesquisa rÃ¡pida
    config_rapida = Configuration(
        query_generator_model="gemini-2.0-flash",
        reflection_model="gemini-2.0-flash", 
        answer_model="gemini-2.5-flash",
        number_of_initial_queries=1,
        max_research_loops=1
    )
    
    # ConfiguraÃ§Ã£o para pesquisa aprofundada
    config_aprofundada = Configuration(
        query_generator_model="gemini-2.5-flash",
        reflection_model="gemini-2.5-pro",
        answer_model="gemini-2.5-pro",
        number_of_initial_queries=5,
        max_research_loops=3
    )
    
    # ConfiguraÃ§Ã£o balanceada
    config_balanceada = Configuration(
        query_generator_model="gemini-2.0-flash",
        reflection_model="gemini-2.5-flash",
        answer_model="gemini-2.5-pro", 
        number_of_initial_queries=3,
        max_research_loops=2
    )
    
    configuracoes = {
        "RÃ¡pida": config_rapida,
        "Aprofundada": config_aprofundada, 
        "Balanceada": config_balanceada
    }
    
    print("ğŸ›ï¸ ConfiguraÃ§Ãµes criadas:")
    for nome, config in configuracoes.items():
        print(f"\nğŸ“Š {nome}:")
        print(f"  - Query model: {config.query_generator_model}")
        print(f"  - Reflection model: {config.reflection_model}")
        print(f"  - Answer model: {config.answer_model}")
        print(f"  - Initial queries: {config.number_of_initial_queries}")
        print(f"  - Max loops: {config.max_research_loops}")
    
    return configuracoes

def exercicio_3_agente_especializado():
    """Simule criaÃ§Ã£o de agente especializado"""
    print("\nğŸ¤– EXERCÃCIO 3: Agente Especializado")
    print("=" * 45)
    
    print("ğŸ¥ Criando: Agente de Pesquisa MÃ©dica")
    
    # Estado especializado para pesquisa mÃ©dica
    estado_medico = {
        "messages": [HumanMessage(content="What are the latest treatments for diabetes?")],
        "initial_search_query_count": 4,  # Mais queries para tÃ³pico complexo
        "max_research_loops": 3,  # Mais loops para precisÃ£o
        "reasoning_model": "gemini-2.5-pro",  # Modelo mais sofisticado
        # Campos customizados (simulaÃ§Ã£o)
        "domain": "medical",
        "evidence_level": "peer_reviewed",
        "time_range": "last_2_years"
    }
    
    print(f"âš•ï¸ ConfiguraÃ§Ã£o do agente mÃ©dico:")
    print(f"  - DomÃ­nio: {estado_medico['domain']}")
    print(f"  - NÃ­vel de evidÃªncia: {estado_medico['evidence_level']}")
    print(f"  - PerÃ­odo: {estado_medico['time_range']}")
    print(f"  - Queries: {estado_medico['initial_search_query_count']}")
    print(f"  - Loops: {estado_medico['max_research_loops']}")
    
    # Simular prompt mÃ©dico personalizado
    prompt_medico = """Como assistente de pesquisa mÃ©dica, gere queries para:
    - Artigos em PubMed e journals mÃ©dicos
    - Ensaios clÃ­nicos e meta-anÃ¡lises  
    - Guidelines de organizaÃ§Ãµes mÃ©dicas
    - Estudos de eficÃ¡cia e seguranÃ§a
    
    TÃ³pico: {research_topic}
    Foque em evidÃªncias cientÃ­ficas de alta qualidade."""
    
    print(f"\nğŸ“‹ Prompt mÃ©dico personalizado criado")
    print(f"   Foco: EvidÃªncias cientÃ­ficas de alta qualidade")
    
    return estado_medico

def exercicio_4_metricas_personalizadas():
    """Defina mÃ©tricas para avaliar diferentes tipos de agente"""
    print("\nğŸ“Š EXERCÃCIO 4: MÃ©tricas Personalizadas")
    print("=" * 45)
    
    metricas = {
        "Pesquisa AcadÃªmica": {
            "sources_quality": "Percentual de fontes peer-reviewed",
            "recency": "MÃ©dia de anos dos artigos citados",
            "citation_count": "NÃºmero de citaÃ§Ãµes incluÃ­das",
            "technical_depth": "NÃ­vel de detalhe tÃ©cnico (1-5)",
            "methodology_coverage": "Cobertura de metodologias (1-5)"
        },
        
        "AnÃ¡lise de Mercado": {
            "data_freshness": "Idade dos dados de mercado (dias)",
            "source_diversity": "NÃºmero de fontes diferentes",
            "geographic_coverage": "RegiÃµes cobertas",
            "financial_metrics": "Quantidade de mÃ©tricas financeiras",
            "trend_analysis": "Qualidade da anÃ¡lise de tendÃªncias (1-5)"
        },
        
        "VerificaÃ§Ã£o de Fatos": {
            "source_independence": "IndependÃªncia das fontes (1-5)",
            "authority_level": "NÃ­vel de autoridade das fontes (1-5)",
            "bias_detection": "DetecÃ§Ã£o de viÃ©s (1-5)",
            "evidence_strength": "ForÃ§a das evidÃªncias (1-5)",
            "contradiction_found": "ContradiÃ§Ãµes identificadas (sim/nÃ£o)"
        }
    }
    
    print("ğŸ“ˆ MÃ©tricas definidas por tipo de agente:")
    for tipo, metrics in metricas.items():
        print(f"\nğŸ¯ {tipo}:")
        for metrica, descricao in metrics.items():
            print(f"  - {metrica}: {descricao}")
    
    return metricas

def exercicio_5_pipeline_customizado():
    """Crie pipeline customizado de processamento"""
    print("\nğŸ”„ EXERCÃCIO 5: Pipeline Customizado")
    print("=" * 45)
    
    # Simular pipeline para diferentes domÃ­nios
    pipelines = {
        "Pesquisa CientÃ­fica": [
            "1. Gerar queries acadÃªmicas",
            "2. Filtrar por peer-review",
            "3. Analisar metodologias",
            "4. Verificar reprodutibilidade",
            "5. Sintetizar evidÃªncias"
        ],
        
        "InteligÃªncia Comercial": [
            "1. Gerar queries de mercado",
            "2. Coletar dados financeiros",
            "3. Analisar competidores",
            "4. Identificar tendÃªncias",
            "5. Projetar oportunidades"
        ],
        
        "Jornalismo Investigativo": [
            "1. Gerar queries investigativas",
            "2. Verificar mÃºltiplas fontes",
            "3. Checar credibilidade",
            "4. Detectar inconsistÃªncias",
            "5. Documentar evidÃªncias"
        ]
    }
    
    print("ğŸ­ Pipelines customizados:")
    for nome, etapas in pipelines.items():
        print(f"\nğŸ”§ {nome}:")
        for etapa in etapas:
            print(f"   {etapa}")
    
    return pipelines

def exercicio_6_teste_personalizado():
    """Execute um teste com customizaÃ§Ãµes"""
    print("\nğŸ§ª EXERCÃCIO 6: Teste Personalizado")
    print("=" * 40)
    
    # Verificar se API estÃ¡ disponÃ­vel
    from dotenv import load_dotenv
    load_dotenv()
    
    if not os.getenv("GEMINI_API_KEY"):
        print("âš ï¸ API Key nÃ£o encontrada - simulando execuÃ§Ã£o")
        
        # Simular resultado
        resultado_simulado = {
            "tipo": "simulaÃ§Ã£o",
            "queries_geradas": ["AI healthcare applications", "machine learning medical diagnosis"],
            "fontes_encontradas": 8,
            "loops_executados": 2,
            "tempo_estimado": "45s",
            "qualidade": "alta precisÃ£o acadÃªmica"
        }
        
        print("ğŸ­ Resultado simulado:")
        for chave, valor in resultado_simulado.items():
            print(f"  - {chave}: {valor}")
        
        return resultado_simulado
    
    else:
        print("ğŸš€ Executando teste real...")
        
        # ConfiguraÃ§Ã£o personalizada para teste
        estado_teste = {
            "messages": [HumanMessage(content="What are the ethical implications of AI in healthcare?")],
            "initial_search_query_count": 2,  # Reduzido para teste
            "max_research_loops": 1,
            "reasoning_model": "gemini-2.0-flash"
        }
        
        try:
            import time
            inicio = time.time()
            resultado = graph.invoke(estado_teste)
            fim = time.time()
            
            print(f"âœ… Teste concluÃ­do em {fim - inicio:.2f}s")
            print(f"ğŸ“Š Queries: {len(resultado.get('search_query', []))}")
            print(f"ğŸ“š Fontes: {len(resultado.get('sources_gathered', []))}")
            
            return resultado
            
        except Exception as e:
            print(f"âŒ Erro no teste: {e}")
            return None

def exercicio_7_ideias_futuras():
    """Brainstorm de ideias para desenvolvimento futuro"""
    print("\nğŸ’¡ EXERCÃCIO 7: Ideias para o Futuro")
    print("=" * 40)
    
    ideias = {
        "Novos DomÃ­nios": [
            "ğŸ§¬ Agente de pesquisa biomÃ©dica",
            "âš–ï¸ Agente de pesquisa jurÃ­dica",
            "ğŸŒ± Agente de sustentabilidade",
            "ğŸ’° Agente de anÃ¡lise financeira",
            "ğŸ”¬ Agente de pesquisa cientÃ­fica"
        ],
        
        "Funcionalidades": [
            "ğŸ“Š Dashboard de mÃ©tricas em tempo real",
            "ğŸ”” Sistema de alertas para novas informaÃ§Ãµes",
            "ğŸ“ˆ AnÃ¡lise de tendÃªncias temporais",
            "ğŸ¤ ColaboraÃ§Ã£o entre mÃºltiplos agentes",
            "ğŸ¯ PersonalizaÃ§Ã£o baseada em histÃ³rico"
        ],
        
        "IntegraÃ§Ãµes": [
            "ğŸ”— APIs de bases de dados especializadas",
            "ğŸ“± Interface mobile nativa",
            "ğŸ—£ï¸ Interface de voz",
            "ğŸ“§ RelatÃ³rios automÃ¡ticos por email",
            "â˜ï¸ Deploy em mÃºltiplas clouds"
        ],
        
        "Melhorias": [
            "ğŸ§  MemÃ³ria de longo prazo",
            "ğŸ¨ VisualizaÃ§Ãµes interativas",
            "ğŸ” Busca semÃ¢ntica avanÃ§ada",
            "âš¡ OtimizaÃ§Ã£o de performance",
            "ğŸ›¡ï¸ SeguranÃ§a e privacidade aprimoradas"
        ]
    }
    
    print("ğŸš€ Ideias para desenvolvimento futuro:")
    for categoria, lista_ideias in ideias.items():
        print(f"\nğŸ“‹ {categoria}:")
        for ideia in lista_ideias:
            print(f"   {ideia}")
    
    return ideias

if __name__ == "__main__":
    print("ğŸ“ EXERCÃCIOS PRÃTICOS - CUSTOMIZAÃ‡Ã•ES E EXPERIMENTOS")
    print("=" * 65)
    
    # Execute todos os exercÃ­cios
    prompts = exercicio_1_prompt_personalizado()
    configs = exercicio_2_configuracoes_especializadas()
    agente = exercicio_3_agente_especializado()
    metricas = exercicio_4_metricas_personalizadas()
    pipelines = exercicio_5_pipeline_customizado()
    teste = exercicio_6_teste_personalizado()
    ideias = exercicio_7_ideias_futuras()
    
    print(f"\nğŸ‰ PARABÃ‰NS! TODOS OS EXERCÃCIOS CONCLUÃDOS!")
    print("=" * 50)
    
    print(f"ğŸ“š O que vocÃª aprendeu:")
    print(f"âœ… Estrutura e arquitetura do agente")
    print(f"âœ… ConfiguraÃ§Ã£o e personalizaÃ§Ã£o")
    print(f"âœ… Prompts e IA generativa")
    print(f"âœ… Estados e fluxo de execuÃ§Ã£o")
    print(f"âœ… CustomizaÃ§Ãµes avanÃ§adas")
    
    print(f"\nğŸš€ PRÃ“XIMOS PASSOS SUGERIDOS:")
    print(f"1. ğŸ”§ Implemente suas prÃ³prias customizaÃ§Ãµes")
    print(f"2. ğŸ¯ Crie agentes para domÃ­nios especÃ­ficos")
    print(f"3. ğŸ“Š Desenvolva mÃ©tricas personalizadas")
    print(f"4. ğŸ”— Integre com outras APIs e serviÃ§os")
    print(f"5. ğŸŒŸ Contribua com melhorias para o projeto")
    
    print(f"\nğŸ’¡ RECURSOS PARA CONTINUAR ESTUDANDO:")
    print(f"ğŸ“– DocumentaÃ§Ã£o LangGraph: https://langchain-ai.github.io/langgraph/")
    print(f"ğŸ¤– Google Gemini API: https://ai.google.dev/docs")
    print(f"ğŸ’¬ Comunidade LangChain: Discord e GitHub")
    
    print(f"\nğŸ–ï¸ VocÃª agora tem conhecimento sÃ³lido sobre agentes LangGraph!")
    print(f"Continue experimentando e construindo coisas incrÃ­veis! ğŸš€")