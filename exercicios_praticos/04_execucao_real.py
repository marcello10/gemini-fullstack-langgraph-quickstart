#!/usr/bin/env python3
"""
ğŸ¯ EXERCÃCIO 4: ExecuÃ§Ã£o Real do Agente
Objetivo: Executar o agente completo e analisar resultados
ATENÃ‡ÃƒO: Requer GEMINI_API_KEY configurada!
"""

import os
import sys
import time
import json
sys.path.append('../backend/src')

from agent.graph import graph
from agent.configuration import Configuration
from langchain_core.messages import HumanMessage
from dotenv import load_dotenv

def verificar_prerequisites():
    """Verifica se todos os prÃ©-requisitos estÃ£o atendidos"""
    print("ğŸ” VERIFICANDO PRÃ‰-REQUISITOS")
    print("=" * 40)
    
    load_dotenv()
    api_key = os.getenv("GEMINI_API_KEY")
    
    if not api_key:
        print("âŒ GEMINI_API_KEY nÃ£o encontrada!")
        print("ğŸ’¡ Para configurar:")
        print("   1. Obtenha uma chave em: https://ai.google.dev/")
        print("   2. Crie arquivo .env na pasta backend/")
        print("   3. Adicione: GEMINI_API_KEY=sua_chave_aqui")
        return False
    
    print(f"âœ… API Key encontrada: {api_key[:10]}...")
    
    try:
        from google.genai import Client
        client = Client(api_key=api_key)
        print("âœ… Cliente Gemini inicializado")
        return True
    except Exception as e:
        print(f"âŒ Erro ao inicializar cliente: {e}")
        return False

def exercicio_1_execucao_simples():
    """Execute o agente com pergunta simples"""
    print("\nğŸš€ EXERCÃCIO 1: ExecuÃ§Ã£o Simples")
    print("=" * 40)
    
    pergunta = "What is artificial intelligence?"
    
    print(f"â“ Pergunta: {pergunta}")
    print(f"â³ Executando agente...")
    
    # Estado inicial simplificado
    estado = {
        "messages": [HumanMessage(content=pergunta)],
        "initial_search_query_count": 2,  # Reduzido para teste rÃ¡pido
        "max_research_loops": 1,  # Apenas 1 loop para teste
        "reasoning_model": "gemini-2.0-flash"
    }
    
    inicio = time.time()
    
    try:
        resultado = graph.invoke(estado)
        fim = time.time()
        
        print(f"âœ… ExecuÃ§Ã£o concluÃ­da em {fim - inicio:.2f}s")
        print(f"ğŸ“Š AnÃ¡lise do resultado:")
        
        # Analise o resultado
        if "messages" in resultado and resultado["messages"]:
            ultima_mensagem = resultado["messages"][-1]
            print(f"  - Tipo da resposta: {ultima_mensagem.type}")
            print(f"  - Tamanho da resposta: {len(ultima_mensagem.content)} chars")
            print(f"  - InÃ­cio da resposta: {ultima_mensagem.content[:100]}...")
        
        if "search_query" in resultado:
            print(f"  - Queries geradas: {len(resultado['search_query'])}")
            print(f"  - Queries: {resultado['search_query']}")
        
        if "sources_gathered" in resultado:
            print(f"  - Fontes coletadas: {len(resultado['sources_gathered'])}")
        
        if "research_loop_count" in resultado:
            print(f"  - Loops executados: {resultado['research_loop_count']}")
        
        return resultado
        
    except Exception as e:
        print(f"âŒ Erro na execuÃ§Ã£o: {e}")
        print(f"ğŸ’¡ Verifique se sua API key estÃ¡ vÃ¡lida")
        return None

def exercicio_2_execucao_detalhada():
    """Execute com configuraÃ§Ã£o mais detalhada"""
    print("\nğŸ”¬ EXERCÃCIO 2: ExecuÃ§Ã£o Detalhada")
    print("=" * 45)
    
    pergunta = "What are the latest developments in renewable energy in 2024?"
    
    print(f"â“ Pergunta: {pergunta}")
    
    # ConfiguraÃ§Ã£o mais robusta
    estado = {
        "messages": [HumanMessage(content=pergunta)],
        "initial_search_query_count": 3,
        "max_research_loops": 2,
        "reasoning_model": "gemini-2.5-pro"
    }
    
    print(f"âš™ï¸ ConfiguraÃ§Ã£o:")
    print(f"  - Queries iniciais: {estado['initial_search_query_count']}")
    print(f"  - Loops mÃ¡ximos: {estado['max_research_loops']}")
    print(f"  - Modelo: {estado['reasoning_model']}")
    
    print(f"â³ Executando (pode levar alguns minutos)...")
    
    inicio = time.time()
    
    try:
        resultado = graph.invoke(estado)
        fim = time.time()
        
        print(f"âœ… ExecuÃ§Ã£o concluÃ­da em {fim - inicio:.2f}s")
        
        # AnÃ¡lise detalhada
        analise_resultado_detalhada(resultado)
        
        return resultado
        
    except Exception as e:
        print(f"âŒ Erro na execuÃ§Ã£o: {e}")
        return None

def analise_resultado_detalhada(resultado):
    """Analisa resultado em detalhes"""
    print(f"\nğŸ“Š ANÃLISE DETALHADA DO RESULTADO:")
    print("=" * 50)
    
    # Mensagens
    if "messages" in resultado:
        print(f"ğŸ’¬ Mensagens: {len(resultado['messages'])}")
        for i, msg in enumerate(resultado["messages"]):
            print(f"  {i+1}. {msg.type}: {len(msg.content)} chars")
    
    # Queries de busca
    if "search_query" in resultado:
        print(f"\nğŸ” Queries de Busca: {len(resultado['search_query'])}")
        for i, query in enumerate(resultado["search_query"]):
            print(f"  {i+1}. {query}")
    
    # Resultados de pesquisa
    if "web_research_result" in resultado:
        print(f"\nğŸŒ Resultados de Pesquisa: {len(resultado['web_research_result'])}")
        for i, res in enumerate(resultado["web_research_result"]):
            print(f"  {i+1}. {len(res)} chars")
    
    # Fontes coletadas
    if "sources_gathered" in resultado:
        print(f"\nğŸ“š Fontes Coletadas: {len(resultado['sources_gathered'])}")
        fontes_unicas = set()
        for fonte in resultado["sources_gathered"]:
            if isinstance(fonte, dict) and "value" in fonte:
                fontes_unicas.add(fonte["value"])
        print(f"  - Fontes Ãºnicas: {len(fontes_unicas)}")
    
    # EstatÃ­sticas
    if "research_loop_count" in resultado:
        print(f"\nğŸ“ˆ EstatÃ­sticas:")
        print(f"  - Loops executados: {resultado['research_loop_count']}")
        
    # Resposta final
    if "messages" in resultado and resultado["messages"]:
        resposta_final = resultado["messages"][-1].content
        print(f"\nğŸ“ Resposta Final:")
        print(f"  - Tamanho: {len(resposta_final)} caracteres")
        print(f"  - Tem citaÃ§Ãµes: {'[' in resposta_final and '](' in resposta_final}")
        print(f"  - PrÃ©via: {resposta_final[:200]}...")

def exercicio_3_comparar_configuracoes():
    """Compare diferentes configuraÃ§Ãµes"""
    print("\nâš–ï¸ EXERCÃCIO 3: Comparando ConfiguraÃ§Ãµes")
    print("=" * 50)
    
    pergunta = "What is machine learning?"
    
    configuracoes = [
        {
            "nome": "RÃ¡pida",
            "config": {
                "initial_search_query_count": 1,
                "max_research_loops": 1,
                "reasoning_model": "gemini-2.0-flash"
            }
        },
        {
            "nome": "PadrÃ£o", 
            "config": {
                "initial_search_query_count": 3,
                "max_research_loops": 2,
                "reasoning_model": "gemini-2.5-flash"
            }
        }
    ]
    
    resultados = []
    
    for setup in configuracoes:
        print(f"\nğŸ§ª Testando configuraÃ§Ã£o: {setup['nome']}")
        
        estado = {
            "messages": [HumanMessage(content=pergunta)],
            **setup["config"]
        }
        
        inicio = time.time()
        
        try:
            resultado = graph.invoke(estado)
            fim = time.time()
            
            resultado_info = {
                "nome": setup["nome"],
                "tempo": fim - inicio,
                "queries": len(resultado.get("search_query", [])),
                "fontes": len(resultado.get("sources_gathered", [])),
                "loops": resultado.get("research_loop_count", 0),
                "tamanho_resposta": len(resultado["messages"][-1].content) if resultado.get("messages") else 0
            }
            
            resultados.append(resultado_info)
            
            print(f"  âœ… Tempo: {resultado_info['tempo']:.2f}s")
            print(f"  ğŸ“Š Queries: {resultado_info['queries']}")
            print(f"  ğŸ“š Fontes: {resultado_info['fontes']}")
            print(f"  ğŸ”„ Loops: {resultado_info['loops']}")
            print(f"  ğŸ“ Resposta: {resultado_info['tamanho_resposta']} chars")
            
        except Exception as e:
            print(f"  âŒ Erro: {e}")
    
    # ComparaÃ§Ã£o final
    if len(resultados) > 1:
        print(f"\nğŸ“Š COMPARAÃ‡ÃƒO FINAL:")
        print("=" * 30)
        for res in resultados:
            print(f"{res['nome']}: {res['tempo']:.2f}s, {res['queries']} queries, {res['fontes']} fontes")

def salvar_resultado(resultado, nome_arquivo="resultado_agente.json"):
    """Salva resultado para anÃ¡lise posterior"""
    if not resultado:
        return
    
    # Converter para formato serializÃ¡vel
    resultado_serializable = {}
    for chave, valor in resultado.items():
        if chave == "messages":
            resultado_serializable[chave] = [
                {"type": msg.type, "content": msg.content} 
                for msg in valor
            ]
        else:
            resultado_serializable[chave] = valor
    
    with open(nome_arquivo, 'w', encoding='utf-8') as f:
        json.dump(resultado_serializable, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ Resultado salvo em: {nome_arquivo}")

if __name__ == "__main__":
    print("ğŸ“ EXERCÃCIOS PRÃTICOS - EXECUÃ‡ÃƒO REAL DO AGENTE")
    print("=" * 60)
    
    # Verificar prÃ©-requisitos
    if not verificar_prerequisites():
        print("\nâŒ PrÃ©-requisitos nÃ£o atendidos!")
        print("Configure a API key e tente novamente.")
        sys.exit(1)
    
    print(f"\nğŸš€ Iniciando exercÃ­cios de execuÃ§Ã£o...")
    
    # ExercÃ­cio 1: Simples
    print(f"\n" + "="*60)
    resultado1 = exercicio_1_execucao_simples()
    if resultado1:
        salvar_resultado(resultado1, "resultado_simples.json")
    
    # Perguntar se quer continuar
    continuar = input(f"\nğŸ¤” Executar exercÃ­cio 2 (mais lento)? [y/N]: ").strip().lower()
    if continuar == 'y':
        resultado2 = exercicio_2_execucao_detalhada()
        if resultado2:
            salvar_resultado(resultado2, "resultado_detalhado.json")
    
    # Perguntar se quer comparar
    comparar = input(f"\nğŸ¤” Executar comparaÃ§Ã£o de configuraÃ§Ãµes? [y/N]: ").strip().lower()
    if comparar == 'y':
        exercicio_3_comparar_configuracoes()
    
    print(f"\nğŸ‰ EXERCÃCIOS CONCLUÃDOS!")
    print(f"ğŸ’¡ PRÃ“XIMOS PASSOS:")
    print(f"  1. Analise os arquivos JSON gerados")
    print(f"  2. Execute: python 05_customizacoes.py")
    print(f"  3. Experimente suas prÃ³prias perguntas!")